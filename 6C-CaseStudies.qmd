```{r, include=FALSE}
set.seed(42)
```

# Case studies

General strategy for analysis:

1.  Define formula via scientific questions + confounders.
2.  Define type of GLM (lm, logistic, Poisson).
3.  Blocks in data -\> Random effects, start with random intercept.

Fit this base model, then do residual checks for

-   Wrong functional form -\> Change fitted function.
-   Wrong distribution-\> Transformation or GLM adjustment.
-   (Over)dispersion -\> Variable dispersion GLM.
-   Heteroskedasticity -\> Model dispersion.
-   Zero-inflation -\> Add ZIP term.
-   ...

And adjust the model accordingly.

## Hurricanes

In <a href="https://www.pnas.org/content/111/24/8782" target="_blank" rel="noopener">https://www.pnas.org/content/111/24/8782</a>, Jung et al. claim that "Female hurricanes are deadlier than male hurricanes".

Specifically, they analyze the number of hurricane fatalities, and claim that there is an effect of the femininity of the name on the number of fatalities, correcting for several possible confounders. They interpret the result as causal (including mediators), claiming that giving only male names to hurricanes would considerably reduce death toll.

The data is available in `DHARMa`{.R}.

```{r chunk_chapter5_task_5, eval=TRUE, message=FALSE, warning=FALSE}
library(DHARMa)
library(mgcv)

str(hurricanes)
```

Some plots:

```{r chunk_chapter5_task_6, eval=TRUE, message=FALSE, warning=FALSE}
plot(hurricanes$MasFem, hurricanes$NDAM, cex = 0.5, pch = 5)
points(hurricanes$MasFem, hurricanes$NDAM, cex = hurricanes$alldeaths/20,
       pch = 4, col= "red")
```

The original model from the paper fits a negative binomial, using `mgcv`.{R}.

```{r chunk_chapter5_task_7, eval=TRUE, message=FALSE, warning=FALSE}
originalModelGAM = gam(alldeaths ~ MasFem * (Minpressure_Updated_2014 + NDAM),
    data = hurricanes, family = nb, na.action = "na.fail")
summary(originalModelGAM)
```

::: {.callout-caution icon="false"}
Tasks:

-   Confirm that you get the same results as in the paper.
-   Have a look at the ?hurricanes to see a residual analysis of the model in the paper
-   Forget what they did. Go back to start, do a causal analysis like we did, and do your own model, diagnosing all residual problems that we discussed. Do you think there is an effect of femininity?
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution

```{r}

library(DHARMa)
?hurricanes

# this is the model fit by Jung et al., fith with glmmTMB
library(glmmTMB)
originalModelGAM = glmmTMB(alldeaths ~ MasFem*
                             (Minpressure_Updated_2014 + scale(NDAM)),
                           data = hurricanes, family = nbinom2)
summary(originalModelGAM)

# note that in the code that I gave you not all predictors were scaled,
# but for looking at the main effect we should scale

originalModelGAM = glmmTMB(alldeaths ~ scale(MasFem) *
                             (scale(Minpressure_Updated_2014) + scale(NDAM)),
                           data = hurricanes, family = nbinom2)
summary(originalModelGAM)

# now main effect is n.s.; it's a bit dodgy, but if you read in the main paper
# they actually argue mainly via ANOVA and significance at high values of NDAM

car::Anova(originalModelGAM)

# in the ANOVA we see that MasFem still n.s. but interactions, and if you
# would calculate effect of MasFem at high NDAM, it is significnat. Something
# like that is argued in the paper. We can emulate this by changing
# NDAM centering to high NDAM

hurricanes$highcenteredNDAM = hurricanes$NDAM - max(hurricanes$NDAM)

originalModelGAM = glmmTMB(alldeaths ~ scale(MasFem) *
                             (scale(Minpressure_Updated_2014) + highcenteredNDAM),
                           data = hurricanes, family = nbinom2)
summary(originalModelGAM)

# OK, let's look at the residuals

# no significant deviation in the general DHARMa plot
res <- simulateResiduals(originalModelGAM)
plot(res)

# but residuals ~ NDAM looks funny, which was pointed
# out by Bob O'Hara in a blog post after publication of the paper
plotResiduals(res, hurricanes$NDAM)

# correcting with a sqrt effect
correctedModel = glmmTMB(alldeaths ~ scale(MasFem) *
                             (scale(Minpressure_Updated_2014) + scale(NDAM) + sqrt(NDAM)),
                          data = hurricanes, family = nbinom2)

res <- simulateResiduals(correctedModel, plot = T)
plotResiduals(res, hurricanes$NDAM)
summary(correctedModel)
car::Anova(correctedModel)

# all gone, only Damage is doing the effect. This wouldn't change with re-scaling probably, as interactions are n.s.

# Moreover, question why they fitted this weird interactions in the first place. A initial model based on a causa analysis could be:

newModel = glmmTMB(alldeaths ~ scale(MasFem) + Minpressure_Updated_2014
                           + NDAM + sqrt(NDAM) + Year,
                           data = hurricanes, family = nbinom2)
summary(newModel)

car::Anova(newModel) # nothing regarding MasFem
```
:::

## Researchers Degrees of Freedom --- Skin Color and Red Cards

In 2018 Silberzahn et al. published a "meta analysis" in *Advances in Methods and Practices in Psychological Science*, where they had provided 29 teams with the same data set to answer one research question: "*\[W\]hether soccer players with dark skin tone are more likely than those with light skin tone to receive red cards from referees*".

**Spoiler**: They found that the "\[a\]nalytic approaches varied widely across the teams, and the estimated effect sizes ranged from 0.89 to 2.93 (Mdn = 1.31) in odds-ratio units", highlighting that different approaches in data analysis can yield significant variation in the results.

You can find the paper "Many Analysts, One Data Set: Making Transparent How Variations in Analytic Choices Affect Results" at: <a href="https://journals.sagepub.com/doi/10.1177/2515245917747646" target="_blank" rel="noopener">https://journals.sagepub.com/doi/10.1177/2515245917747646</a>.

Task: Do a re-analysis of the data as if you were the 30th team to contribute the results to the meta analysis.

-   Download the data file "CrowdstormingDataJuly1st.csv" here: <a href="https://osf.io/fv8c3/" target="_blank" rel="noopener">https://osf.io/fv8c3/</a>.

-   Variable explanations are provided in the README: <a href="https://osf.io/9yh4x/" target="_blank" rel="noopener">https://osf.io/9yh4x/</a>.

-   Analyze the data. Given the research question, the selected variables are:

    1.  Response variable: 'redCards' (+'yellowReds'?).
    2.  Multiple variables, potentially accounting for confounding, offsetting, grouping, ... are included in the data.
    3.  primary predictors: 'rater1', 'rater2'

    -   These variables reflect ratings of "two independent raters blind to the research question who, based on their profile photo, categorized players on a 5-point scale ranging from (1) very light skin to (5) very dark skin.
    -   Make sure that 'rater1' and 'rater2' are rescaled to the range 0 ... 1 as described in the paper ("This variable was rescaled to be bounded by 0 (very light skin) and 1 (very dark skin) prior to the final analysis, to ensure consistency of effect sizes across the teams of analysts. The raw ratings were rescaled to 0, .25, .50, .75, and 1 to create this new scale.")

-   Research the concept of **odd ratios** and convert your effect estimate into this format. Are your results within the range of estimates from the 29 teams in Silberzahn et al. (2018)?

-   Have a look at the other modelling teams. Do you understand the models they fit?

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution
:::

## Scouting Ants

Look at the dataset EcoData::scoutingAnts, and find out if there are really scouting Ants in Lasius Niger.

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution
:::

## Owls

Look at the Owl data set in the `glmmTMB` package. The initial hypothesis is

```{r chunk_chapter5_task_3, message=FALSE, warning=FALSE}
library(glmmTMB)

m1 = glm(SiblingNegotiation ~ FoodTreatment*SexParent + offset(log(BroodSize)),
         data = Owls , family = poisson)
res = simulateResiduals(m1)
plot(res)
```

::: {.callout-caution icon="false"}
#### Tasks

The offset is a special command that can be used in all regression models. It means that we include an effect with effect size 1.

The offset has a special importance in models with a log link function, because with these models, we have y = exp(x ...), so if you do y = exp(x + log(BroodSize) ) and use exp rules, this is y = exp(x) \* exp(log(BroodSize)) = y = exp(x) \* BroodSize, so this makes the response proportional to BroodSize. This trick is often used in log link GLMs to make the response proportional to Area, Sampling effort, etc.

Now, try to improve the model with everything we have discussed so far.
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution

```{r chunk_chapter5_task_4, message=FALSE, warning=FALSE}
m1 = glmmTMB::glmmTMB(SiblingNegotiation ~ FoodTreatment * SexParent
  + (1|Nest) + offset(log(BroodSize)), data = Owls , family = nbinom1,
  dispformula = ~ FoodTreatment + SexParent,
  ziformula = ~ FoodTreatment + SexParent)
summary(m1)

res = simulateResiduals(m1, plot = T)

testDispersion(m1)
testZeroInflation(m1)
```
:::

## Snails

```{r, warning=FALSE, message=FALSE}
library(EcoData)
library(glmmTMB)
library(lme4)
library(DHARMa)
library(tidyverse)
?EcoData::snails
```

Look at the Snails data set in the `EcoData` package, and find out which environmental and/or seasonal predictors i) explain the total abundance and ii) the infection rate of the three species.

Tasks:

1.  Model the summed total abundance of the three species (Bulinus_tot)

2.  Model the infection rate of all three species (Bulinuts_pos_tot)

3.  Optional: Model the species individually (BP_tot, BF_tot, BT_tot)

4.  Optional: Fit a multivariate (joint) species distribution model

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution for total Abundance of *Bulinus* (glmm)

Prepare+scale data:

```{r}
library(lme4)
library(glmmTMB)
library(DHARMa)
data = EcoData::snails
data$sTemp_Water = scale(data$Temp_Water)
data$spH = scale(data$pH)
data$swater_speed_ms = scale(data$water_speed_ms)
data$swater_depth = scale(data$water_depth)
data$sCond = scale(data$Cond)
data$swmo_prec = scale(data$wmo_prec)
data$syear = scale(data$year)
data$sLat = scale(data$Latitude)
data$sLon = scale(data$Longitude)

# Let's remove NAs beforehand:
rows = rownames(model.matrix(Bulinus_tot~sTemp_Water + spH + sLat + sLon + sCond + seas_wmo+ swmo_prec + swater_speed_ms + swater_depth + syear + duration + locality + site_irn + coll_date, data = data))
data = data[rows, ]

```

1.  **Poisson-glmm**

First model, glmm with `family = poisson`, random intercepts (site_irn nested within locality), and an offset:

```{r}
model1 = glmer(Bulinus_tot~
                 offset(log(duration)) + site_type  + sTemp_Water + seas_wmo+ spH +
                 sCond + swmo_prec + swater_speed_ms + swater_depth + syear +
                 (1|locality/site_irn) +  (1|coll_date),
              data = data,  family = poisson, control = glmerControl(optimizer = "bobyqa"))
summary(model1)
```

**Residual checks:**

Check residuals:

```{r}
res = simulateResiduals(model1, plot = TRUE, re.form = NULL)
```

Does not look great -\> dispersion problems:

Overdispersion can be caused by misfit.

```{r}
testDispersion(res, alternative = "greater")
```

s.

Underdispersion:

```{r}
testDispersion(res, alternative = "less")
```

n.s

Check for missing random slopes:

```{r, fig.width=8, fig.height=12}
plot(model1, resid(.) ~ swater_depth | coll_date, abline = 1)
```

```{r}

model2 = glmer(Bulinus_tot~
                 offset(log(duration)) + site_type  + sTemp_Water + seas_wmo+ spH +
                 sCond + swmo_prec + swater_speed_ms + swater_depth + syear +
                 (1|locality/site_irn) +  (spH + swater_depth||coll_date),
              data = data,  family = poisson, control = glmerControl(optimizer = "bobyqa"))
summary(model2)
simulateResiduals(model2, plot = TRUE, re.form = NULL)
```

Switch to negative binomial

2.  **NegBinom-glmm**

```{r}
model3 = glmmTMB(Bulinus_tot~
                 offset(log(duration)) + site_type + sTemp_Water + seas_wmo+ spH + sCond +
                 swmo_prec + swater_speed_ms + swater_depth + syear +
                 (1|locality/site_irn) + (spH + swater_depth||coll_date),
              data = data,  family = nbinom2())
summary(model3)
plot(simulateResiduals(model3))
```

Residuals look better but they are unconditioned!

Check conditional residuals:

```{r}
pred = predict(model3, re.form = NULL, type = "response")
simulations = sapply(1:1000, function(i) rnbinom(length(pred),size = summary(model3)$sigma, mu =  pred))
res = createDHARMa(simulations, model.frame(model3)[,1], pred)
plot(res)
```

Better!

```{r}
testDispersion(res, alternative = "less")
testDispersion(res, alternative = "greater")
```

There is underdispersion.

Use the `dispformula` to make the dispersion depend on the covariates:

```{r}
model4 = glmmTMB(Bulinus_tot~
                 offset(log(duration)) + site_type + sTemp_Water + seas_wmo+ spH + sCond +
                 swmo_prec + swater_speed_ms + swater_depth + syear +
                 (1|locality/site_irn) + (spH + swater_depth||coll_date),
                 dispformula = ~site_type + sTemp_Water + seas_wmo+ spH + sCond +
                 swmo_prec + swater_speed_ms + swater_depth + syear,
              data = data,  family = nbinom2)
summary(model4)
```

Check conditional residuals:

```{r}
pred = predict(model4, re.form = NULL, type = "response")
pred_dispersion = predict(model4, re.form = NULL, type = "disp")
simulations = sapply(1:1000, function(i) rnbinom(length(pred),size = pred_dispersion, mu =  pred))
res = createDHARMa(simulations, model.frame(model4)[,1], pred)
plot(res)
```

Better.

Check for temporal and spatial autocorrelation (we detrended both by using year and random intercept for sites):

```{r}
## Spatial
res2 = recalculateResiduals(res, group = c(data$site_irn))
groupLocations = aggregate(cbind(data$sLat, data$sLon ), list( data$site_irn), mean)
testSpatialAutocorrelation(res2, x = groupLocations$V1, y = groupLocations$V2)


## Temporal
res2 = recalculateResiduals(res, group = as.factor(data$month),)
testTemporalAutocorrelation(res2, time = unique(as.factor(data$month)))

```

Both n.s.

3.  **Bonus: NegBinom-glmm with spatial and temporal autocorrelation**

Both are n.s. But let's account for spatial and temporal autocorrelation anyway (just for fun):

```{r}
numFac = numFactor(data$sLat, data$sLon)
group = factor(rep(1, nrow(data)))
data$fmonth = as.factor(data$month)
model5 = glmmTMB(Bulinus_tot~
                 offset(log(duration)) + site_type + sTemp_Water + seas_wmo+ spH + sCond +
                 swmo_prec + swater_speed_ms + swater_depth + syear +
                 (1|locality/site_irn) + (spH + swater_depth||coll_date) +
                 exp(0+numFac|group) + ar1(0+fmonth|site_irn),
                 dispformula = ~site_type + sTemp_Water + seas_wmo+ spH + sCond +
                 swmo_prec + swater_speed_ms + swater_depth + syear,
              data = data,  family = nbinom2)
```
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution for prevalence of *Bulinus* (glmm)

Prepare+scale data:

```{r}
data = EcoData::snails
data$sTemp_Water = scale(data$Temp_Water)
data$spH = scale(data$pH)
data$swater_speed_ms = scale(data$water_speed_ms)
data$swater_depth = scale(data$water_depth)
data$sCond = scale(data$Cond)
data$swmo_prec = scale(data$wmo_prec)
data$syear = scale(data$year)
data$sLat = scale(data$Latitude)
data$sLon = scale(data$Longitude)

# Let's remove NAs beforehand:
rows = rownames(model.matrix(cbind(Bulinus_pos_tot, Bulinus_tot-Bulinus_pos_tot)~sTemp_Water + spH + sLat + sLon + sCond + seas_wmo+ swmo_prec + swater_speed_ms + swater_depth + syear + duration + locality + site_irn + coll_date, data = data))
data = data[rows, ]

```

```{r}
model1 = glmer(cbind(Bulinus_pos_tot, Bulinus_tot-Bulinus_pos_tot)~
                 site_type + sTemp_Water + seas_wmo+ spH + sCond +
                 swmo_prec + swater_speed_ms + swater_depth + syear +
                 (1|locality/site_irn) +  (spH + swater_depth||coll_date),
              data = data,  family = binomial)
summary(model1)
plot(simulateResiduals(model1, res.form=NULL))
```
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution of multivariate (joint) species distribution model

```{r}
library(tidyverse)
data = EcoData::snails
data$sTemp_Water = scale(data$Temp_Water)
data$spH = scale(data$pH)
data$swater_speed_ms = scale(data$water_speed_ms)
data$swater_depth = scale(data$water_depth)
data$sCond = scale(data$Cond)
data$swmo_prec = scale(data$wmo_prec)
data$syear = scale(data$year)
data$sLat = scale(data$Latitude)
data$sLon = scale(data$Longitude)

# Let's remove NAs beforehand:
rows = rownames(model.matrix(cbind(Bulinus_pos_tot, Bulinus_tot-Bulinus_pos_tot)~sTemp_Water + spH + sLat + sLon + sCond + seas_wmo+ swmo_prec + swater_speed_ms + swater_depth + syear + duration + locality + site_irn + coll_date, data = data))
data = data[rows, ]

data =
  data %>% pivot_longer(cols = c("BP_tot", "BF_tot", "BT_tot"),
                      names_to = "Species",
                      values_to = "Abundance" )

numFac = numFactor(data$sLat, data$sLon)
group = factor(rep(1, nrow(data)))
data$fmonth = as.factor(data$month)

modelJoint = glmmTMB(Abundance ~ 0 +
                 offset(log(duration)) + Species + Species:(site_type +
                    sTemp_Water + seas_wmo+ spH + sCond + swmo_prec +
                      swater_speed_ms + swater_depth + syear) +
                    exp(0+numFac|group:Species) + ar1(0+fmonth|site_irn:Species) +
                     (spH + swater_depth||coll_date:Species) +
                 rr(Species + 0|locality:site_irn, d = 2), # Multivariate structure
                 dispformula = ~0+Species+Species:(sTemp_Water + spH + syear),
              data = data,  family = nbinom2())


```

Conditional residuals:

```{r}
pred = predict(modelJoint, re.form = NULL, type = "response")
pred_dispersion = predict(modelJoint, re.form = NULL, type = "disp")
simulations = sapply(1:1000, function(i) rnbinom(length(pred),size = pred_dispersion, mu =  pred))
res = createDHARMa(simulations, model.frame(modelJoint)[,1], pred)
plot(res)
```

Unconditional residuals:

```{r}
plot(simulateResiduals(modelJoint))
```
:::

## Seed bank

```{r, warning=FALSE,message=FALSE}
library(EcoData)
library(glmmTMB)
library(lme4)
library(lmerTest)
library(DHARMa)
library(tidyverse)
?EcoData::seedBank
```

The seedBank data set in the EcoData package includes observation on seed bank presence and size in different vegetaition plots.

The scientific question is if the ability of plants to build a seed bank depends on their seed traits (see help).

The data also contains data on environmental factors and plant traits. You should consider if it is useful to add them to the analysis. 


Tasks:

1.  Fit a lm/lmm with SBDensity as response

2.  Add phylogenetic correlation structure

3.  Fit a glm/glmm with SBPA as response and with phylogenetic correlation structure

::: {.callout-caution icon="false"}
#### Solution for SBDensity (lmm)

Prepare+scale data:

```{r}
data = as.data.frame(EcoData::seedBank)
data$sAltitude = scale(data$Altitude)
data$sSeedMass = scale(data$SeedMass)
data$sSeedShape = scale(data$SeedShape)
data$sSeedN = scale(data$SeedN)
data$sSeedPr = scale(data$SeedPr)
data$sDormRank = scale(data$DormRank)
data$sTemp = scale(data$Temp)
data$sHum = scale(data$Humidity)
data$sNitro = scale(data$Nitrogen)
data$sGrazing = scale(data$Grazing)

# Let's remove NAs beforehand:
rows = rownames(model.matrix(SBDensity~sAltitude + sSeedMass + sSeedShape + sSeedN +
                               sSeedPr + sDormRank + sTemp + sHum + sNitro +
                               sGrazing + Site + Species, data = data))
data = data[rows, ]
```


The response is highly skewed, so it makes sense to log-transform:


```{r}
hist(data$SBDensity)
data$logSBDensity = log(data$SBDensity + 1)
```

Let's fit a base model

* added seed traits
* added environment as possible confounders

```{r}

model1 = lmer(logSBDensity~
                sSeedMass + sSeedShape + sSeedN + sSeedPr +
                sDormRank + sAltitude + sHum + sNitro + sGrazing +
                (1|Site) + (1|Species),
              data = data)

summary(model1)
```

**Residual checks:**

```{r, fig.width=9, fig.height=12}
plot(simulateResiduals(model1, re.form=NULL))
```

Check for missing random slopes:

```{r}
plot(model1, resid(.) ~ sAltitude | Species, abline = 1)
```

Add random slope for sAltitude (but without a correlation between the two random effects):

```{r}

model2 = lmer(logSBDensity ~
                sSeedMass + sSeedShape + sSeedN + sSeedPr +
                sDormRank + sAltitude + sHum + sNitro + sGrazing +
                (1|Site) + (sAltitude + sSeedN |Species),
              data = data)
summary(model2)

```

Check residuals:

```{r}
res = simulateResiduals(model2, re.form=NULL, plot=TRUE)
```

Residuals do not look perfect, variance is not constant:

```{r}
plotResiduals(res, data$sAltitude)
plotResiduals(res, data$sSeedMass)
```

2.  **Modeling variance with glmmTMB**

```{r}
model3 = glmmTMB(log(SBDensity+1)~
                sSeedMass + sSeedShape + sSeedN + sSeedPr +
                sDormRank + sAltitude + sHum + sNitro + sGrazing +
                (1|Site) + (sAltitude||Species),
              dispformula = ~sAltitude + sSeedMass + sSeedShape +
                sDormRank + sAltitude + sHum + sNitro + sGrazing,
              data = data)
summary(model3)
plot(simulateResiduals(model3))
```

Residuals look worse but they are unconditioned
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution for SBDensity (lmm) with phylogenetic correlation structure

Prepare phylogeny:

```{r}
library(ape)
library(geiger)
species = unique(data$Species)
species_df = data.frame(Species = species)
rownames(species_df) = species
obj = name.check(plantPhylo, species_df)

# drop rest of the species
phyl.upd = drop.tip(plantPhylo, obj$tree_not_data)
summary(phyl.upd)

# check the names in the tree and in the data set
name.check(phyl.upd, species_df)

phyl.upd2 = multi2di(phyl.upd)
```

nlme:

```{r}
library(nlme)
model4 = gls(log(SBDensity+1)~
                sSeedMass + sSeedShape + sSeedN + sSeedPr +
                sDormRank + sAltitude + sHum + sNitro + sGrazing,
             correlation = corBrownian(phy = phyl.upd2, form =~ Species),
             data = data)
summary(model4)

```

glmmTMB (not perfect because lack of support of specific phylogenetic correlation structures):

```{r}
dist_phylo = ape::cophenetic.phylo(phyl.upd2) # create distance matrix
correlation_matrix = vcv(phyl.upd2)[unique(data$Species), unique(data$Species)]

###
#the following code was taken from https://github.com/glmmTMB/glmmTMB/blob/master/misc/fixcorr.rmd
as.theta.vcov <- function(Sigma,corrs.only=FALSE) {
    logsd <- log(diag(Sigma))/2
    cr <- cov2cor(Sigma)
    cc <- chol(cr)
    cc <- cc %*% diag(1 / diag(cc))
    corrs <- cc[upper.tri(cc)]
    if (corrs.only) return(corrs)
    ret <- c(logsd,corrs)
    return(ret)
}
corrs = as.theta.vcov(correlation_matrix, corrs.only=TRUE)
#####

data$dummy = factor(rep(0, nrow(data)))
nsp = length(unique(data$Species))
model5 = glmmTMB(log(SBDensity+1)~
                sSeedMass + sSeedShape + sSeedN + sSeedPr +
                sDormRank + sAltitude + sHum + sNitro + sGrazing +
                (1|Site) + (0+sAltitude||Species) +
                (1+Species|dummy),
              dispformula = ~sAltitude + sSeedMass + sSeedShape,
              map=list(theta=factor(c(0,0, rep(1,nsp),rep(NA,length(corrs))) )),
              start=list(theta=c(0,0, rep(0,nsp),corrs)),
              data = data)
summary(model5)
simulateResiduals(model5, plot = TRUE) # Unconditional simulations
```
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution for SBPA (glmm)

Prepare+scale data:

```{r}
data = as.data.frame(EcoData::seedBank)
data$sAltitude = scale(data$Altitude)
data$sSeedMass = scale(data$SeedMass)
data$sSeedShape = scale(data$SeedShape)
data$sSeedN = scale(data$SeedN)
data$sSeedPr = scale(data$SeedPr)
data$sDormRank = scale(data$DormRank)
data$sTemp = scale(data$Temp)
data$sHum = scale(data$Humidity)
data$sNitro = scale(data$Nitrogen)
data$sGrazing = scale(data$Grazing)

# Let's remove NAs beforehand:
rows = rownames(model.matrix(~sAltitude + sSeedMass + sSeedShape + sSeedN +
                               sSeedPr + sDormRank + sTemp + sHum + sNitro +
                               sGrazing + Site + Species, data = data))
data = data[rows, ]

```

```{r}

model1 = glmer(SBPA~
                sSeedMass + sSeedShape + sSeedN + sSeedPr +
                sDormRank + sAltitude + sHum + sNitro + sGrazing +
                (1|Site) + (sAltitude||Species),
              data = data, family = binomial(), control = glmerControl(optimizer = "bobyqa"))
summary(model1)
```

**Residual checks:**

Check residuals:

```{r}
res = simulateResiduals(model1, re.form=NULL, plot=TRUE)
```

Residuals look fine!

**With phylogenetic correlation structure:**

```{r}
dist_phylo = ape::cophenetic.phylo(phyl.upd2) # create distance matrix
correlation_matrix = vcv(phyl.upd2)[unique(data$Species), unique(data$Species)]

###
#the following code was taken from https://github.com/glmmTMB/glmmTMB/blob/master/misc/fixcorr.rmd
as.theta.vcov <- function(Sigma,corrs.only=FALSE) {
    logsd <- log(diag(Sigma))/2
    cr <- cov2cor(Sigma)
    cc <- chol(cr)
    cc <- cc %*% diag(1 / diag(cc))
    corrs <- cc[upper.tri(cc)]
    if (corrs.only) return(corrs)
    ret <- c(logsd,corrs)
    return(ret)
}
corrs = as.theta.vcov(correlation_matrix, corrs.only=TRUE)
#####

data$dummy = factor(rep(0, nrow(data)))
nsp = length(unique(data$Species))
model6 = glmmTMB(SBPA~
                sSeedMass + sSeedShape + sSeedN + sSeedPr +
                sDormRank + sAltitude + sHum + sNitro + sGrazing +
                (1|Site) + (0+sAltitude||Species) +
                (1+Species|dummy),
              map=list(theta=factor(c(0,0, rep(1,nsp),rep(NA,length(corrs))) )),
              start=list(theta=c(0,0, rep(0,nsp),corrs)),
              family = binomial,
              data = data)
simulateResiduals(model6, plot = TRUE)
```

Conditional simulations:

```{r}
pred = predict(model6, re.form = NULL, type = "response")
simulations = sapply(1:1000, function(i) rbinom(length(pred),1, pred))
res = createDHARMa(simulations, model.frame(model6)[,1], pred)
plot(res)
```
:::

## Snouter

Fit one of the responses in the snouter datset against the predictors rain + djungle (see ?snouter). Check for spatial autocorrelation and proceed to fitting a spatial model if needed. See the data set's help for details on the variables.

```{r eval = F}
library(EcoData)
str(snouter)
```

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution
:::
